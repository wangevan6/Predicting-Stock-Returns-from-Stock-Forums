{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS1003 Final Project \n",
    "## Step 2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "On2VG-e5LygR"
   },
   "source": [
    "1. Get tokens for each forum\n",
    "2. Run them through them through the LDA to get X variables for regression\n",
    "3. Run a logistic regression on them (all topics from a single post) to predict positive (1 for increase) or negative (0 for decrease)\n",
    "4. Compare with our predictions based on sentiment analysis (accuracy)\n",
    "\n",
    "Our poster will have one section dedicated to data collection, one section dedicated to data preprocessing (cleaning, tokenizing), one section dedicated to sentiment analysis, one section dedicated to LDA, one section dedicated to sLDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EP7geglfIkCq",
    "outputId": "58f5dced-167e-4000-dbe4-9ad8add85740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.8633093525179856\n",
      "Topic 0: shuttle program information software edu available nasa image data space\n",
      "Topic 1: bit format images files gif edu graphics file image jpeg\n",
      "Topic 2: team know game good time year like just don think\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load data\n",
    "data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), categories=['sci.space', 'rec.sport.baseball', 'comp.graphics'])\n",
    "docs = data.data\n",
    "y = np.where(data.target > 0, 1, 0)  # Create a binary response variable\n",
    "\n",
    "# Create a document-term matrix\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "doc_term_matrix = vectorizer.fit_transform(docs)\n",
    "\n",
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_term_matrix, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train LDA\n",
    "lda = LatentDirichletAllocation(n_components=3, random_state=0)\n",
    "X_topics = lda.fit_transform(X_train)\n",
    "\n",
    "# Use the document-topic distribution as features to predict the response variable\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_topics, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Model score:\", reg.score(X_topics, y_train))\n",
    "\n",
    "# Print topics\n",
    "words = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {topic_idx}: {' '.join([words[i] for i in topic.argsort()[-10:]])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IA_rDYl9W4G7",
    "outputId": "fa1d9b2c-bfc3-4e3f-969e-e787ab1fd669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['comp.graphics', 'rec.sport.baseball', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "print(data.target_names[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "kG8HOR1T5HkI",
    "outputId": "add64449-6075-4c93-b412-1fb248ff208d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"wsbfinal2\",\n  \"rows\": 401,\n  \"fields\": [\n    {\n      \"column\": \"Post ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 401,\n        \"samples\": [\n          \"i4uwkc\",\n          \"i3dzih\",\n          \"fb3z1h\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 398,\n        \"samples\": [\n          \"Can I post DD without getting filtered yet Sigh ...\",\n          \"From the Scientist who posted the NVAX DD: Updates about recent COVID Vaccine news and today's price action for $NVAX &amp; $MRNA\",\n          \"[DD] I have corona virus and I downloaded robinhood 36 hours ago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Publish Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 401,\n        \"samples\": [\n          \"2020-08-06 16:26:48\",\n          \"2020-08-04 6:07:23\",\n          \"2020-02-28 23:58:43\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Selftext\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 401,\n        \"samples\": [\n          \"Fastly provides real-time content delivery network services. It offers edge cloud platform, edge software development kit (SDK), content delivery and image optimization, video and streaming, cloud security, load balancing, and managed CDN.  &amp;#x200B;  # What differentiates Fastly from Akami?   **Why go with Fastly (investor)**  Because people do not understand the market, technology, and how the carrier business works. These are the same people that say \\u201c5G is coming\\u201d not realizing it is already here and has no effect on the carrier business.  **Why go with Fastly (customer)**  Sadly in technology sometimes people go with the cheapest provider then get their dick kicked in later, we call those CIO\\u2019s looking for jobs soon.  Akami - has a better suite of products / services. There backbone CDN is Zayo and old Level 3 dark fiber on 30-year contracts. Akami datacenter footprints are in the cheaper carrier hotels but you don\\u2019t need fancy. Akami has a better API.  Fastly - a smaller suite of product services. Their backbone is lit services from ATT and Century link on short term contracts. Their data center footprint is from a reseller in a reseller in a data center company. Mediocre API at best.  The core of the business is the backbone. Since Fastly does not control their ATT and Century link can groom them (lose redundancy or increase latency) without Fastly even knowing. Since the backbone is lit every time Fastly needs to increase the size of the connection they have to call ATT or CenturyLink and renegotiate a circuit and wait for them to turn it up. Akami just changes optics on a switch since they are lighting and managing their own dark fiber. They also will never get groomed.  **TLDR:** Basically Fastly is the choice for cash-poor companies or the guy that soon will be replaced. But it does have it\\u2019s placed, there is never a silver bullet in tech, but the mountain they have to climb from an investor perspective is monumental and long. I would work for them (if they had a solid RSU program), I would consider a long term share position (if I was younger) but not a short term explosion unless the unthinkable happens and someone scoops them up for 16 - 20 times EBITDA, but unlikely that high, because their customer base is already split between CDN providers and them, do not own a lot. All their network is easily matched by anyone, they are not sitting on the last strands of fiber on some awesome route or in a key data center that is at capacity.  &amp;#x200B;  Fastly CRUSHED earnings yesterday, they're doing really well in terms of growth. However, they disclosed that their largest client, which also accounts for 12% of sales, is TikTok. Shares are down 19% today on that news given TikTok could be banned in the US if not acquired by Sept 15.  &amp;#x200B;  IMO, I don't think Microsoft or any company would let TikTok get banned in the US. I'm playing on the fact that the acquisition will go through, and when it does, this stock will P.O.P.\",\n          \"HD Had missed EPS by -7.82% last quarter due to a number of reasons majority being huge over head from HomeDepot allowing employees paid time off and for those who worked double overtime that cost was $640 million to be exact... this qt they should have figured out the majority of cost issues and cut back on PTO and over time also revenue will undoubtedly be beaten.   Lowe\\u2019s had it down from the beginning with a 34.6% EPS gain last quarter around the time this article was written maybe they where not as kind to their employees? Or where better prepared.  Either way what is your guys thoughts do you figure HD has this problem solved by now analysts even a few weeks after earnings seemed hopeful of their direction.   Source: https://www.google.com/amp/s/www.cnbc.com/amp/2020/05/19/home-depot-hd-earnings-q1-2020.html  For you lazy autist this is all you need to buy calls \\ud83d\\ude18  Jefferies equity analyst Jonathan Matuszewski said in a note to clients. He added that limiting costs associated with the company's response to the coronavirus will also be key to protecting earnings.  \\\"Given HD's commentary, it will be key to understand the maintenance or potential loosening of such actions heading into the typically-promotional Memorial Day Weekend,\\\" he said in the note. \\\"If the home improvement centers can constrain incremental expenses to meet outsized traffic while still protecting customers/employees, EPS should improve.\\\"   WHICH they have obviously done if you have visited a Home Depot recently they have mask and hand santanziter at the front door. No wait to get in and they are busy as hell.\",\n          \"After me and the wife went to bed, she went to go fuck her boyfriend, and I woke up throwing up $TENDIES from being a \\ud83c\\udf08 \\ud83d\\udc3b this past week. Watched some $NFLX on my $AAPL laptop so I think \\ud83e\\udd14 definitely buys calls on those.    The 1918 influenza pandemic was exceptional as it killed \\ud83d\\udc80 at least 50 million people worldwide \\ud83c\\udf0d making it the worst influenza pandemic in recent recorded history \\ud83d\\udcc6 Clinicians \\ud83c\\udf36 and scientists \\ud83d\\udc68\\u200d\\ud83d\\udd2c of the time were grappling with many unknowns, and what added to the confusion was the erroneous belief that the disease was caused by a bacterium  \\u0336  not a virus  \\u0336  called Pfeiffer\\u2019s bacillus (a gram-negative bacterium \\ud83e\\uddeb now recognized as Haemophilus influenzae). It wasn\\u2019t for another 30 years that people \\ud83d\\udc68 would understand that the 1918 pandemic \\ud83e\\udda0 virus that infected 30% of the world\\u2019s population was an influenza A (H1N1) \\ud83e\\udda0 . Because of its impact, the 1918 pandemic is sometimes referred to as the \\u201cMother of all Pandemics,\\u201d and it continues to inspire research on its origins and the relationship between the 1918 virus and other influenza viruses.   TLDR: $NFLX 3/20 $278.5c and $AAPL 3/20 230c calls printing Monday morning.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SentScore\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0024602372044800138,\n        \"min\": -0.01321585903,\n        \"max\": 0.015625,\n        \"num_unique_values\": 328,\n        \"samples\": [\n          0.0002534854246,\n          0.001047943411,\n          0.001718213058\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tickers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 251,\n        \"samples\": [\n          \"YUM\",\n          \"['NKE', 'GE']\",\n          \"MGM\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unnamed: 7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 121,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"By Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment W(1)/L(0)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Position\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Actual Win/L\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Win/L\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Binary Actual \",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "wsbfinal2"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3691f24e-b627-4e98-8345-29522d2a5935\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>Selftext</th>\n",
       "      <th>SentScore</th>\n",
       "      <th>Tickers</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Actual Ticker</th>\n",
       "      <th>By Sentiment</th>\n",
       "      <th>Sentiment W(1)/L(0)</th>\n",
       "      <th>Actual Position</th>\n",
       "      <th>Actual Win/L</th>\n",
       "      <th>Predicted Win/L</th>\n",
       "      <th>Binary Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ejnlo3</td>\n",
       "      <td>$CRC DD</td>\n",
       "      <td>2020-01-03 23:18:04</td>\n",
       "      <td>Alright autists, keeping up with the Daddy Ira...</td>\n",
       "      <td>-0.001141</td>\n",
       "      <td>['OXY', 'IR', 'HAL', 'SLB']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CRC</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Long</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eomcpm</td>\n",
       "      <td>AMZN DD INSIDE (LONG)</td>\n",
       "      <td>2020-01-14 15:00:29</td>\n",
       "      <td>**NOTE: This write up was done by u/soundofree...</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>['AMZN', 'F']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>Long</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>epc4op</td>\n",
       "      <td>Yet another $SPCE DD for all ye autists</td>\n",
       "      <td>2020-01-16 1:37:41</td>\n",
       "      <td>This is the ride of our generation. You didn‚Äôt...</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>['AAPL', 'NFLX', 'AMZN', 'FB', 'GOOG']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPCE</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "      <td>Long</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ermnes</td>\n",
       "      <td>FDX DD</td>\n",
       "      <td>2020-01-21 0:37:05</td>\n",
       "      <td>This afternoon I had my handler drive me to a ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>FDX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FDX</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "      <td>Long</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eshzd5</td>\n",
       "      <td>[DD] Wuhan Coronavirus: $APT, $MMM</td>\n",
       "      <td>2020-01-22 20:50:57</td>\n",
       "      <td>$APT makes protective equipment and tends to d...</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>MMM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APT</td>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "      <td>Long</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3691f24e-b627-4e98-8345-29522d2a5935')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3691f24e-b627-4e98-8345-29522d2a5935 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3691f24e-b627-4e98-8345-29522d2a5935');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-d21a2f75-7f20-43ea-a823-cece6a2dca62\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d21a2f75-7f20-43ea-a823-cece6a2dca62')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-d21a2f75-7f20-43ea-a823-cece6a2dca62 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  Post ID                                    Title         Publish Date  \\\n",
       "0  ejnlo3                                  $CRC DD  2020-01-03 23:18:04   \n",
       "1  eomcpm                    AMZN DD INSIDE (LONG)  2020-01-14 15:00:29   \n",
       "2  epc4op  Yet another $SPCE DD for all ye autists   2020-01-16 1:37:41   \n",
       "3  ermnes                                   FDX DD   2020-01-21 0:37:05   \n",
       "4  eshzd5       [DD] Wuhan Coronavirus: $APT, $MMM  2020-01-22 20:50:57   \n",
       "\n",
       "                                            Selftext  SentScore  \\\n",
       "0  Alright autists, keeping up with the Daddy Ira...  -0.001141   \n",
       "1  **NOTE: This write up was done by u/soundofree...   0.001189   \n",
       "2  This is the ride of our generation. You didn‚Äôt...   0.005563   \n",
       "3  This afternoon I had my handler drive me to a ...   0.000000   \n",
       "4  $APT makes protective equipment and tends to d...   0.001010   \n",
       "\n",
       "                                  Tickers  Unnamed: 6  Unnamed: 7  \\\n",
       "0             ['OXY', 'IR', 'HAL', 'SLB']         NaN         NaN   \n",
       "1                           ['AMZN', 'F']         NaN         NaN   \n",
       "2  ['AAPL', 'NFLX', 'AMZN', 'FB', 'GOOG']         NaN         NaN   \n",
       "3                                     FDX         NaN         NaN   \n",
       "4                                     MMM         NaN         NaN   \n",
       "\n",
       "  Actual Ticker By Sentiment Sentiment W(1)/L(0) Actual Position Actual Win/L  \\\n",
       "0           CRC            S                   0            Long            1   \n",
       "1          AMZN            L                   1            Long            1   \n",
       "2          SPCE            l                   1            Long            1   \n",
       "3           FDX            l                   1            Long            0   \n",
       "4           APT            l                   1            Long            1   \n",
       "\n",
       "  Predicted Win/L Binary Actual   \n",
       "0               0              1  \n",
       "1               1              1  \n",
       "2               1              1  \n",
       "3               0              1  \n",
       "4               1              1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wsbfinal2 = pd.read_csv(\"wsbFinal2.csv\")\n",
    "wsbfinal2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YxvcsxdGCwrB",
    "outputId": "5ad10975-8256-4ff3-a041-a970e1b2afa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Alright autists, keeping up with the Daddy Ira...\n",
       "1     **NOTE: This write up was done by u/soundofree...\n",
       "2     This is the ride of our generation. You didn‚Äôt...\n",
       "3     This afternoon I had my handler drive me to a ...\n",
       "4     $APT makes protective equipment and tends to d...\n",
       "5     We would all agree that Microsoft is a blue ch...\n",
       "6     Wuhan virus is only killing old people who don...\n",
       "7     FAANGS are trading at stupid high P/Es. Amazon...\n",
       "8     Buy CHRW leaps today. The truckload transporta...\n",
       "9     Hi Fuckers.  I work in tech sales for a digita...\n",
       "10    As you may have heard Macau shut down all casi...\n",
       "11    Your favorite $MSFT shill is back for round th...\n",
       "12       Your favorite $MSFT shill is back for round...\n",
       "13     Your favorite $MSFT shill is back for round t...\n",
       "14    No bullshit story just JRE #1425 with Garrett ...\n",
       "15    Alright, fellow autists, new and ready to be s...\n",
       "16    So here is some decent DD... I work for one of...\n",
       "17    Staged stores as you have probably heard is co...\n",
       "18    Why are any of you autists not buying into AMD...\n",
       "19    Alright everyone looking for the next meme, he...\n",
       "20    How does this make sense? When I literally do ...\n",
       "21    Here's the deal - WSB is no longer on r/all, h...\n",
       "22    * Okay. Let's get some shit out in the clear f...\n",
       "23    Alright now that the virus is ramping up how d...\n",
       "24    üåàüêª Stay the F out...  So a little about Guarda...\n",
       "25    Earnings are 2/26 BMO.   Market cap is 280 mil...\n",
       "26    https://i.redd.it/egmblpkcj2j41.png  Walmart i...\n",
       "27    Let's look at a put option on Microsoft. The w...\n",
       "28    So you autists are scared that MSFT not meetin...\n",
       "29    Here's a few key bits of evidence that prove t...\n",
       "30    Okay so AMD is currently down a little over 20...\n",
       "31    1. Incubation period of up to 27 days with vir...\n",
       "32    Rather than trying to convince you, I am just ...\n",
       "33    After me and the wife went to bed, she went to...\n",
       "34    Alright fellow autists, here‚Äôs why GILD has th...\n",
       "35    Listen up, you smoothed brain retards. You thi...\n",
       "36    I will try to make this DD short, simple and q...\n",
       "37    okay i know you guys might have some difficult...\n",
       "38    All right boys, listen up. This is more for th...\n",
       "39    Alright autists, listen up. Duke Energy ($DUK)...\n",
       "40    I live in LA but I spent the last 10 years liv...\n",
       "41    **Tl;dr ‚Äì we are nowhere near the bottom of ho...\n",
       "42    Just want to keep it brief and to the point. S...\n",
       "43    If you're not in bear gang, it's not too late ...\n",
       "44    What if I told that this ancient US Car maker ...\n",
       "45    There is currently a price war going on with c...\n",
       "46    Did you know BAC is down 25% in the last 3 wee...\n",
       "47    http://imgur.com/gallery/xSWod0Q  Obviously al...\n",
       "48    Activision has beaten their EPS 4/4 since last...\n",
       "49    So, after reading constant idiots talking abou...\n",
       "50    &amp;#x200B;  Link: [https://finance.yahoo.com...\n",
       "51    Listen up autists, this is a freebie. Whoever ...\n",
       "Name: Selftext, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = wsbfinal2.Selftext.iloc[0:52]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "d7hVJbYoDEJ_"
   },
   "outputs": [],
   "source": [
    "df_y = wsbfinal2[\"Binary Actual \"]\n",
    "df_y = df_y.dropna()\n",
    "dfy = df_y[0:52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aqxx_OUJ9VXf",
    "outputId": "fb14d030-c012-45d5-e02b-aa610b0d32f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.7272727272727273\n",
      "Topic 0: stock disney oil market know just like debt price year\n",
      "Topic 1: 2020 drug coronavirus gild gilead virus com www https remdesivir\n",
      "Topic 2: market cloud azure like www amd com https amp amazon\n"
     ]
    }
   ],
   "source": [
    "# Create a document-term matrix\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "doc_term_matrix = vectorizer.fit_transform(test_df)\n",
    "\n",
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_term_matrix, dfy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train LDA\n",
    "lda = LatentDirichletAllocation(n_components=3, random_state=0)\n",
    "X_topics = lda.fit_transform(X_train)\n",
    "\n",
    "# Use the document-topic distribution as features to predict the response variable\n",
    "reg = LogisticRegression()\n",
    "reg.fit(X_topics, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "X_topics_test = lda.transform(X_test)\n",
    "print(\"Model score:\", reg.score(X_topics_test, y_test))\n",
    "\n",
    "# Print topics\n",
    "words = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "  print(f\"Topic {topic_idx}: {' '.join([words[i] for i in topic.argsort()[-10:]])}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
